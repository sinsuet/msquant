from openai import OpenAI
import os
import json
from alpha_engine import analyze_factor 

# ==========================================
# é…ç½®éƒ¨åˆ†ï¼šåˆ‡æ¢ä¸º Qwen (é€šä¹‰åƒé—®)
# ==========================================
# 1. æ›¿æ¢ä¸ºä½ çš„é˜¿é‡Œäº‘ DashScope API Key (é€šå¸¸ä»¥ sk- å¼€å¤´)
#    è·å–åœ°å€: https://bailian.console.aliyun.com/
DASHSCOPE_API_KEY = "sk-d807fcc0e09e40b9a3d6f736aad39c15"

# 2. åˆå§‹åŒ– Clientï¼Œæ ¸å¿ƒæ˜¯ä¿®æ”¹ base_url
client = OpenAI(
    api_key=DASHSCOPE_API_KEY, 
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"  # é˜¿é‡Œäº‘å…¼å®¹ OpenAI çš„æ¥å£åœ°å€
)

def llm_judge(factor_A_report, factor_B_report, market_context):
    
    prompt = f"""
    ã€è§’è‰²ã€‘
    ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡åŒ–æŠ•èµ„ç»„åˆç»ç†ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®å½“å‰çš„å¸‚åœºç¯å¢ƒï¼Œå¯¹æ¯”ä¸¤ä¸ª Alpha ç­–ç•¥çš„è¡¨ç°ï¼Œå¹¶é€‰æ‹©ä¸‹ä¸ªå­£åº¦æ›´é€‚åˆçš„ä¸€ä¸ªã€‚

    ã€å½“å‰å¸‚åœºç¯å¢ƒã€‘
    {market_context}

    ã€é€‰æ‰‹ A: {factor_A_report['name']}ã€‘
    - å…¬å¼: {factor_A_report['formula']}
    - ICå‡å€¼ (é¢„æµ‹èƒ½åŠ›): {factor_A_report['IC_Mean']} (æ­£æ•°è¡¨ç¤ºæ­£ç›¸å…³ï¼Œè´Ÿæ•°è¡¨ç¤ºè´Ÿç›¸å…³)
    - å¹´åŒ–æ”¶ç›Š: {factor_A_report['Annual_Return']}
    - å¤æ™®æ¯”ç‡: {factor_A_report['Sharpe']}

    ã€é€‰æ‰‹ B: {factor_B_report['name']}ã€‘
    - å…¬å¼: {factor_B_report['formula']}
    - ICå‡å€¼ (é¢„æµ‹èƒ½åŠ›): {factor_B_report['IC_Mean']}
    - å¹´åŒ–æ”¶ç›Š: {factor_B_report['Annual_Return']}
    - å¤æ™®æ¯”ç‡: {factor_B_report['Sharpe']}

    ã€ä»»åŠ¡ã€‘
    è¯·åˆ†æå“ªä¸ªå› å­åœ¨å½“å‰å¸‚åœºç¯å¢ƒä¸‹è¡¨ç°æ›´å¥½ï¼Ÿ
    1. ç®€å•åˆ†æä¸¤ä¸ªå› å­çš„é€»è¾‘ï¼ˆæ˜¯åŠ¨é‡è¿˜æ˜¯åè½¬ï¼Ÿï¼‰ã€‚
    2. ç»“åˆå¸‚åœºç¯å¢ƒè¯´æ˜ä¸ºä»€ä¹ˆé€‰å®ƒã€‚
    3. æœ€ç»ˆç»™å‡ºç»“è®ºï¼šèƒœè€…æ˜¯ A è¿˜æ˜¯ Bã€‚
    """

    print(f"æ­£åœ¨å’¨è¯¢ AI åˆ†æå¸ˆ (ä½¿ç”¨æ¨¡å‹: qwen-plus)...")
    
    try:
        response = client.chat.completions.create(
            # å¯é€‰æ¨¡å‹: 
            # - qwen-max (èƒ½åŠ›æœ€å¼ºï¼Œæ¥è¿‘ GPT-4)
            # - qwen-plus (æ€§ä»·æ¯”é«˜ï¼Œèƒ½åŠ›å‡è¡¡)
            # - qwen-turbo (é€Ÿåº¦å¿«ï¼Œä¾¿å®œ)
            model="qwen-plus", 
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡åŒ–é‡‘èåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå› å­è¡¨ç°ä¸å¸‚åœºé£æ ¼çš„åŒ¹é…åº¦ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2 # é™ä½éšæœºæ€§ï¼Œè®©åˆ†ææ›´ç†æ€§
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"è°ƒç”¨ Qwen API å¤±è´¥: {e}"

if __name__ == "__main__":
    # --- æ¨¡æ‹Ÿè¿è¡Œ ---

    # 1. å‡†å¤‡å¸‚åœºç¯å¢ƒæè¿° (è®ºæ–‡ä¸­çš„ Context)
    # è¿™é‡Œæˆ‘ä»¬ç”¨ä¸­æ–‡æè¿°ï¼ŒQwen ç†è§£èµ·æ¥ä¼šæ›´ç²¾å‡†
    market_status = """
    è¿‘æœŸå¸‚åœºå‘ˆç°éœ‡è¡ä¸‹è¡Œè¶‹åŠ¿ï¼Œæˆäº¤é‡æŒç»­èç¼©ã€‚
    å®è§‚å±‚é¢ï¼Œç»æµå¤è‹ä¸åŠé¢„æœŸï¼Œå¸‚åœºç¼ºä¹æ˜ç¡®çš„ä¸»çº¿é¢˜æã€‚
    åœ¨è¿™ç§å­˜é‡åšå¼ˆçš„ç‰¹å¾ä¸‹ï¼Œé«˜ä½è‚¡å¼€å§‹è¡¥è·Œï¼Œä½ä¼°å€¼æ¿å—é˜²å¾¡å±æ€§å‡¸æ˜¾ã€‚
    """

    # 2. è®¡ç®—ä¸¤ä¸ªå› å­çš„çœŸå®è¡¨ç° (è°ƒç”¨ä¸Šä¸€æ­¥å†™çš„å¼•æ“)
    print("æ­£åœ¨è®¡ç®—å› å­æŒ‡æ ‡...")
    # å› å­A: åŠ¨é‡ (è¿½æ¶¨æ€è·Œ) -> åœ¨éœ‡è¡ä¸‹è·Œå¸‚ä¸­é€šå¸¸è¡¨ç°è¾ƒå·®
    report_A = analyze_factor("Momentum_10D", "CLOSE - DELAY(CLOSE, 10)")
    
    # å› å­B: å‡å€¼å›å½’ (è·Œå¤šäº†ä¹°) -> åœ¨éœ‡è¡å¸‚ä¸­å¯èƒ½è¡¨ç°è¾ƒå¥½
    report_B = analyze_factor("Reversion_5D", "MA(CLOSE, 5) - CLOSE")

    # æ‰“å°ç®€æŠ¥çœ‹çœ‹
    print(f"\n[å› å­A ç®€æŠ¥]: {json.dumps(report_A, ensure_ascii=False)}")
    print(f"[å› å­B ç®€æŠ¥]: {json.dumps(report_B, ensure_ascii=False)}\n")

    # 3. AI è£å†³
    if isinstance(report_A, dict) and isinstance(report_B, dict):
        decision = llm_judge(report_A, report_B, market_status)
        
        print("="*40)
        print("ğŸ¤– é€šä¹‰åƒé—®(Qwen) æŠ•èµ„æ€»ç›‘çš„å†³ç­–æŠ¥å‘Š")
        print("="*40)
        print(decision)
    else:
        print("å› å­è®¡ç®—å‡ºé”™ï¼Œæ— æ³•è¿›è¡Œ PKã€‚è¯·æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸‹è½½å®Œæˆã€‚")